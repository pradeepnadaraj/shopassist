{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1spGkHmtPUx",
        "outputId": "4b36ab17-adf9-4043-d658-be6811f2a9e0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ngrok tunnel: NgrokTunnel: \"https://4a43-104-196-130-33.ngrok-free.app\" -> \"http://localhost:5001\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5001\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:09:40] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:09:41] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:10:16] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:10:17] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:10:57] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n",
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:11:00] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:11:00] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:11:23] \"\u001b[32mPOST /end_conversation HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:11:23] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:11:30] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:11:30] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:11:41] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:11:42] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:12:09] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:12:09] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:12:20] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:12:21] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:12:45] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:12:46] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:12:56] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:12:57] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:13:09] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:13:09] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:13:20] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:13:21] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:13:41] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isNo\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:13:42] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intent confirmation isYes\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:14:57] \"\u001b[32mPOST /conversation HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Oct/2024 16:14:58] \"GET / HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, redirect, url_for, render_template, request\n",
        "from pyngrok import ngrok\n",
        "\n",
        "from functions import (\n",
        "    initialize_conversation,\n",
        "    initialize_conv_reco,\n",
        "    get_chat_model_completions,\n",
        "    moderation_check,\n",
        "    intent_confirmation_layer,\n",
        "    compare_laptops_with_user,\n",
        "    recommendation_validation,\n",
        "    get_user_requirement_string,\n",
        "    get_chat_completions_func_calling\n",
        ")\n",
        "import openai\n",
        "import ast\n",
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "openai.api_key=open(\"OpenAI_API_Key.txt\",'r').read().strip()\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "conversation_bot = []\n",
        "conversation = initialize_conversation()\n",
        "introduction = get_chat_model_completions(conversation)\n",
        "conversation_bot.append({'bot':introduction})\n",
        "top_3_laptops = None\n",
        "\n",
        "\n",
        "@app.route(\"/\")\n",
        "def default_func():\n",
        "    global conversation_bot, conversation, top_3_laptops\n",
        "    return render_template(\"conversation_bot.html\", name_xyz = conversation_bot)\n",
        "\n",
        "@app.route(\"/end_conversation\", methods = ['POST','GET'])\n",
        "def end_conv():\n",
        "    global conversation_bot, conversation, top_3_laptops\n",
        "    conversation_bot = []\n",
        "    conversation = initialize_conversation()\n",
        "    introduction = get_chat_model_completions(conversation)\n",
        "    conversation_bot.append({'bot':introduction})\n",
        "    top_3_laptops = None\n",
        "    return redirect(url_for('default_func'))\n",
        "\n",
        "@app.route(\"/conversation\", methods = ['POST'])\n",
        "def invite():\n",
        "    global conversation_bot, conversation, top_3_laptops, conversation_reco\n",
        "    user_input = request.form[\"user_input_message\"]\n",
        "    prompt = 'Remember your system message and that you are an intelligent laptop assistant. So, you only help with questions around laptop.'\n",
        "    moderation = moderation_check(user_input)\n",
        "    if moderation == 'Flagged':\n",
        "        return redirect(url_for('end_conv'))\n",
        "\n",
        "    if top_3_laptops is None:\n",
        "        conversation.append({\"role\": \"user\", \"content\": user_input + prompt})\n",
        "        conversation_bot.append({'user':user_input})\n",
        "\n",
        "        response_assistant = get_chat_model_completions(conversation)\n",
        "\n",
        "\n",
        "        moderation = moderation_check(response_assistant)\n",
        "        if moderation == 'Flagged':\n",
        "            return redirect(url_for('end_conv'))\n",
        "\n",
        "        confirmation = intent_confirmation_layer(response_assistant)\n",
        "\n",
        "        print('Intent confirmation is' + confirmation)\n",
        "\n",
        "        moderation = moderation_check(confirmation)\n",
        "        if moderation == 'Flagged':\n",
        "            return redirect(url_for('end_conv'))\n",
        "\n",
        "        if \"No\" in confirmation:\n",
        "            conversation.append({\"role\": \"assistant\", \"content\": response_assistant})\n",
        "            conversation_bot.append({'bot':response_assistant})\n",
        "        else:\n",
        "            response = get_user_requirement_string(response_assistant)\n",
        "            result = get_chat_completions_func_calling(response, True)\n",
        "            conversation_bot.append({'bot':\"Thank you for providing all the information. Kindly wait, while I fetch the products: \\n\"})\n",
        "\n",
        "            top_3_laptops = compare_laptops_with_user(result)\n",
        "\n",
        "            validated_reco = recommendation_validation(top_3_laptops)\n",
        "\n",
        "            if len(validated_reco) == 0:\n",
        "                conversation_bot.append({'bot':\"Sorry, we do not have laptops that match your requirements. Connecting you to a human expert. Please end this conversation.\"})\n",
        "\n",
        "            conversation_reco = initialize_conv_reco(validated_reco)\n",
        "            recommendation = get_chat_model_completions(conversation_reco)\n",
        "\n",
        "            moderation = moderation_check(recommendation)\n",
        "            if moderation == 'Flagged':\n",
        "                return redirect(url_for('end_conv'))\n",
        "\n",
        "            conversation_reco.append({\"role\": \"user\", \"content\": \"This is my user profile\" + response})\n",
        "\n",
        "            conversation_reco.append({\"role\": \"assistant\", \"content\": recommendation})\n",
        "            conversation_bot.append({'bot':recommendation})\n",
        "\n",
        "\n",
        "    else:\n",
        "        conversation_reco.append({\"role\": \"user\", \"content\": user_input})\n",
        "        conversation_bot.append({'user':user_input})\n",
        "\n",
        "        response_asst_reco = get_chat_model_completions(conversation_reco)\n",
        "\n",
        "        moderation = moderation_check(response_asst_reco)\n",
        "        if moderation == 'Flagged':\n",
        "            return redirect(url_for('end_conv'))\n",
        "\n",
        "        conversation.append({\"role\": \"assistant\", \"content\": response_asst_reco})\n",
        "        conversation_bot.append({'bot':response_asst_reco})\n",
        "    return redirect(url_for('default_func'))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    public_url = ngrok.connect(5001)\n",
        "    print(\"ngrok tunnel:\", public_url)\n",
        "    app.run(port=5001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2o6BVasxITWe6GcAYwIboeIgsic_3AmpkFJ4sdhQ2F27aMANA\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03BfI0VHxJuo",
        "outputId": "41fcc69c-57f3-49a6-eb97-8d65b2fd7a8a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZESuzO3IvXDO",
        "outputId": "7e4477bc-5e29-47ba-a4de-c27466c62b0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.2\n"
          ]
        }
      ]
    }
  ]
}